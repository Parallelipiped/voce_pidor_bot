# -*- coding: utf-8 -*-
import sys
import warnings
import time
import torch
import os
import wave
import codecs
import numpy as np
import soundfile as sf
from typing import Optional
from contextlib import contextmanager
import shutil
import json

# –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –∫–æ–¥–∏—Ä–æ–≤–∫—É –¥–ª—è stdout
if sys.stdout.encoding != 'utf-8':
    sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer, 'strict')
if sys.stderr.encoding != 'utf-8':
    sys.stderr = codecs.getwriter('utf-8')(sys.stderr.buffer, 'strict')

# –û—Ç–∫–ª—é—á–∞–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
warnings.filterwarnings("ignore")

@contextmanager
def open_wav_file(path: str, mode: str = 'rb'):
    """–ë–µ–∑–æ–ø–∞—Å–Ω–æ –æ—Ç–∫—Ä—ã–≤–∞–µ—Ç WAV —Ñ–∞–π–ª —Å –ø–æ–º–æ—â—å—é –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–≥–æ –º–µ–Ω–µ–¥–∂–µ—Ä–∞"""
    file = None
    try:
        file = wave.open(path, mode)
        yield file
    finally:
        if file:
            file.close()

def create_temp_copy(path: str) -> Optional[str]:
    """–°–æ–∑–¥–∞–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—É—é –∫–æ–ø–∏—é —Ñ–∞–π–ª–∞ –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
    try:
        temp_path = path + '.processing'
        shutil.copy2(path, temp_path)
        return temp_path
    except Exception as e:
        print(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—É—é –∫–æ–ø–∏—é —Ñ–∞–π–ª–∞: {str(e)}", file=sys.stderr)
        return None

def check_file(path: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –∏ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å —Ñ–∞–π–ª–∞"""
    if not os.path.exists(path):
        print(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {path}", file=sys.stderr)
        return False
    
    if not os.path.isfile(path):
        print(f"–ü—É—Ç—å –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —Ñ–∞–π–ª–æ–º: {path}", file=sys.stderr)
        return False
    
    try:
        with open(path, 'rb') as f:
            # –ü—Ä–æ–±—É–µ–º –ø—Ä–æ—á–∏—Ç–∞—Ç—å –Ω–∞—á–∞–ª–æ —Ñ–∞–π–ª–∞
            f.read(1024)
        return True
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ —Ñ–∞–π–ª—É {path}: {str(e)}", file=sys.stderr)
        return False

def check_wav_file(path: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç WAV —Ñ–∞–π–ª –Ω–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å"""
    try:
        path = os.path.abspath(path)
        print(f"–ü—Ä–æ–≤–µ—Ä—è—é —Ñ–∞–π–ª: {path}", file=sys.stderr)
        
        if not os.path.exists(path):
            print(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {path}", file=sys.stderr)
            return False
        
        if not os.path.isfile(path):
            print(f"–ü—É—Ç—å –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —Ñ–∞–π–ª–æ–º: {path}", file=sys.stderr)
            return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
        size = os.path.getsize(path)
        if size == 0:
            print(f"–§–∞–π–ª –ø—É—Å—Ç–æ–π: {path}", file=sys.stderr)
            return False
        print(f"–†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {size} –±–∞–π—Ç", file=sys.stderr)
        
        try:
            with open_wav_file(path) as wav:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã WAV —Ñ–∞–π–ª–∞
                channels = wav.getnchannels()
                width = wav.getsampwidth()
                rate = wav.getframerate()
                frames = wav.getnframes()
                
                print(f"WAV –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:", file=sys.stderr)
                print(f"- –ö–∞–Ω–∞–ª—ã: {channels}", file=sys.stderr)
                print(f"- –ë–∏—Ç–Ω–æ—Å—Ç—å: {width * 8} –±–∏—Ç", file=sys.stderr)
                print(f"- –ß–∞—Å—Ç–æ—Ç–∞: {rate} –ì—Ü", file=sys.stderr)
                print(f"- –§—Ä–µ–π–º–æ–≤: {frames}", file=sys.stderr)
                print(f"- –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {frames / rate:.2f} —Å–µ–∫", file=sys.stderr)
                
                if channels != 1:
                    print(f"–ù–µ–≤–µ—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–Ω–∞–ª–æ–≤: {channels}", file=sys.stderr)
                    return False
                if width != 2:  # 16-bit
                    print(f"–ù–µ–≤–µ—Ä–Ω–∞—è –±–∏—Ç–Ω–æ—Å—Ç—å: {width * 8}", file=sys.stderr)
                    return False
                if rate != 16000:
                    print(f"–ù–µ–≤–µ—Ä–Ω–∞—è —á–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏: {rate}", file=sys.stderr)
                    return False
            return True
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ WAV —Ñ–∞–π–ª–∞ {path}: {str(e)}", file=sys.stderr)
            return False
            
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ —Ñ–∞–π–ª–∞ {path}: {str(e)}", file=sys.stderr)
        return False

def check_audio_file(audio_path: str) -> None:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç WAV —Ñ–∞–π–ª –∏ –µ–≥–æ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã."""
    if not os.path.exists(audio_path):
        raise FileNotFoundError(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {audio_path}")
    
    print(f"–ü—Ä–æ–≤–µ—Ä—è—é —Ñ–∞–π–ª: {audio_path}", file=sys.stderr)
    
    # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–π–ª–µ
    file_size = os.path.getsize(audio_path)
    print(f"–†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {file_size} –±–∞–π—Ç", file=sys.stderr)
    
    # –ß–∏—Ç–∞–µ–º WAV –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    with sf.SoundFile(audio_path) as f:
        print("WAV –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:", file=sys.stderr)
        print(f"- –ö–∞–Ω–∞–ª—ã: {f.channels}", file=sys.stderr)
        print(f"- –ë–∏—Ç–Ω–æ—Å—Ç—å: {f.subtype}", file=sys.stderr)
        print(f"- –ß–∞—Å—Ç–æ—Ç–∞: {f.samplerate} –ì—Ü", file=sys.stderr)
        print(f"- –§—Ä–µ–π–º–æ–≤: {f.frames}", file=sys.stderr)
        print(f"- –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {f.frames / f.samplerate:.2f} —Å–µ–∫", file=sys.stderr)

def load_audio(audio_path: str) -> np.ndarray:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∞—É–¥–∏–æ —Ñ–∞–π–ª –≤ –ø–∞–º—è—Ç—å."""
    audio, _ = sf.read(audio_path, dtype='float32')
    return audio

def format_sentence(text: str) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –æ–¥–Ω–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ"""
    if not text:
        return ""
    # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã –≤ –Ω–∞—á–∞–ª–µ –∏ –∫–æ–Ω—Ü–µ
    text = text.strip()
    # –î–µ–ª–∞–µ–º –ø–µ—Ä–≤—É—é –±—É–∫–≤—É –∑–∞–≥–ª–∞–≤–Ω–æ–π
    text = text[0].upper() + text[1:] if text else ""
    # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ—á–∫—É –≤ –∫–æ–Ω—Ü–µ –µ—Å–ª–∏ –Ω–µ—Ç –∑–Ω–∞–∫–æ–≤ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
    if not text[-1] in '.!?':
        text += '.'
    return text

def format_text(text: str) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç –¥–ª—è –ª—É—á—à–µ–π —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏"""
    # –ó–∞–º–µ–Ω—è–µ–º —á–∞—Å—Ç—ã–µ —Å–ª–æ–≤–∞-–ø–∞—Ä–∞–∑–∏—Ç—ã
    filler_words = {
        '–∫–æ—Ä–æ—á–µ': '–ö–æ—Ä–æ—á–µ –≥–æ–≤–æ—Ä—è,',
        '–≤–∞—É–ª—è': '–≤—É–∞–ª—è',
        '–≤–æ—Ç': '',
    }
    
    # –°–ª–æ–≤–∞, —Ç—Ä–µ–±—É—é—â–∏–µ –∑–∞–ø—è—Ç–æ–π –ø–µ—Ä–µ–¥ –Ω–∏–º–∏
    comma_words = [
        '–∫–æ—Ç–æ—Ä—ã–π', '–∫–æ—Ç–æ—Ä–∞—è', '–∫–æ—Ç–æ—Ä–æ–µ', '–∫–æ—Ç–æ—Ä—ã–µ',
        '–≥–¥–µ', '–∫—É–¥–∞', '–æ—Ç–∫—É–¥–∞', '–∫–æ–≥–¥–∞', '–ø–æ–∫–∞',
        '–µ—Å–ª–∏', '—á—Ç–æ–±—ã', '–ø–æ—Ç–æ–º—É', '–ø–æ—ç—Ç–æ–º—É',
        '–∫–∞–∫', '–±—É–¥—Ç–æ', '—Å–ª–æ–≤–Ω–æ', '—Ç–æ—á–Ω–æ',
        '—á—Ç–æ', '—á–µ–º', '—Ö–æ—Ç—è', '–ø—É—Å—Ç—å'
    ]
    
    # –†–∞–∑–±–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
    sentences = []
    current = []
    
    # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —Å–ª–æ–≤–∞ –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥–æ–µ
    words = text.split()
    for i, word in enumerate(words):
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ —Å–ª–æ–≤–∞
        if not word:
            continue
            
        # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–ø—è—Ç—É—é –ø–µ—Ä–µ–¥ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–º–∏ —Å–ª–æ–≤–∞–º–∏
        if word.lower() in comma_words and current:
            if not current[-1].endswith(('.', ',', '!', '?', ':', ';')):
                current[-1] = current[-1] + ','
                
        # –ó–∞–º–µ–Ω—è–µ–º —Å–ª–æ–≤–∞-–ø–∞—Ä–∞–∑–∏—Ç—ã
        word_lower = word.lower()
        if word_lower in filler_words:
            if filler_words[word_lower]:
                current.append(filler_words[word_lower])
            continue
            
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–ª–æ–≤–æ
        current.append(word)
        
        # –ï—Å–ª–∏ —Å–ª–æ–≤–æ –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è –Ω–∞ –∑–Ω–∞–∫ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è, –Ω–∞—á–∏–Ω–∞–µ–º –Ω–æ–≤–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ
        if word.endswith(('.', '!', '?')):
            if current:
                sentences.append(format_sentence(' '.join(current)))
                current = []
                
        # –ï—Å–ª–∏ —Å–ª–µ–¥—É—é—â–µ–µ —Å–ª–æ–≤–æ –Ω–∞—á–∏–Ω–∞–µ—Ç –Ω–æ–≤–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ
        elif i < len(words) - 1:
            next_word = words[i + 1].lower()
            if next_word in ['–∞', '–Ω–æ', '–∏', '–∏–ª–∏']:
                if current:
                    sentences.append(format_sentence(' '.join(current) + '.'))
                    current = []
    
    # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ
    if current:
        sentences.append(format_sentence(' '.join(current)))
    
    # –°–æ–±–∏—Ä–∞–µ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —Å –¥–≤—É–º—è –ø—Ä–æ–±–µ–ª–∞–º–∏ –º–µ–∂–¥—É –Ω–∏–º–∏
    return '  '.join(sentences)

def clean_text(text: str) -> str:
    """–û—á–∏—â–∞–µ—Ç —Ç–µ–∫—Å—Ç –æ—Ç HTML —Ç–µ–≥–æ–≤ –∏ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤"""
    # –ó–∞–º–µ–Ω—è–µ–º <br> –∏ </br> –Ω–∞ –ø–µ—Ä–µ–Ω–æ—Å —Å—Ç—Ä–æ–∫–∏
    text = text.replace('<br>', '\n').replace('</br>', '\n')
    # –ó–∞–º–µ–Ω—è–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫ –Ω–∞ –æ–¥–∏–Ω
    text = '\n'.join(line.strip() for line in text.splitlines() if line.strip())
    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç
    text = format_text(text)
    return text

def transcribe_audio(audio_path: str) -> str:
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª
        print(f"–ù–∞—á–∏–Ω–∞—é —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞: {audio_path}", file=sys.stderr)
        check_audio_file(audio_path)

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞—É–¥–∏–æ –≤ –ø–∞–º—è—Ç—å
        print("Loading audio file into memory...", file=sys.stderr)
        audio = load_audio(audio_path)
        print(f"Audio loaded: shape={audio.shape}, dtype={audio.dtype}", file=sys.stderr)

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
        device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}", file=sys.stderr)
        if device == "cuda":
            print(f"GPU: {torch.cuda.get_device_name(0)}", file=sys.stderr)
        
        import whisper
        start_time = time.time()

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
        config_path = os.path.join(os.path.dirname(audio_path), "config.json")
        print(f"Looking for config at: {config_path}", file=sys.stderr)
        
        if not os.path.exists(config_path):
            print(f"Config file not found at: {config_path}", file=sys.stderr)
            print("Using default configuration", file=sys.stderr)
            config = {
                "speech": {
                    "model": "medium",
                    "language": "ru",
                    "use_gpu": True
                }
            }
        else:
            print("Loading configuration from file", file=sys.stderr)
            with open(config_path, 'r') as f:
                config = json.load(f)
            print(f"Loaded config: {config}", file=sys.stderr)

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
        print("Loading model...", file=sys.stderr)
        print("–≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ", file=sys.stderr)
        model = whisper.load_model(config["speech"]["model"]).to(device)
        model_load_time = time.time() - start_time
        print(f"Model loaded in {model_load_time:.2f} seconds", file=sys.stderr)

        # –†–∞—Å–ø–æ–∑–Ω–∞–µ–º —Ä–µ—á—å
        print(f"Transcribing audio data...", file=sys.stderr)
        transcribe_start = time.time()
        result = model.transcribe(audio, language=config["speech"]["language"])
        transcribe_time = time.time() - transcribe_start
        print(f"Transcription completed in {transcribe_time:.2f} seconds", file=sys.stderr)

        # –û—á–∏—â–∞–µ–º –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        text = clean_text(result["text"].strip())
        
        # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤ stderr –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        total_time = time.time() - start_time
        stats = f"\n\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:\n‚è± –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏: {model_load_time:.1f}—Å\n‚åõÔ∏è –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ: {transcribe_time:.1f}—Å\nüïê –û–±—â–µ–µ –≤—Ä–µ–º—è: {total_time:.1f}—Å"
        print(f"–†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç:\n{text}", file=sys.stderr)
        print(f"–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:{stats}", file=sys.stderr)
        
        # –í—ã–≤–æ–¥–∏–º —Ç–µ–∫—Å—Ç –≤ stdout –¥–ª—è Go
        print(text)
        sys.stdout.flush()
        
        return text

    except ImportError as e:
        print(f"Error importing whisper: {str(e)}", file=sys.stderr)
        sys.exit(1)
    except Exception as e:
        print(f"Error: {str(e)}", file=sys.stderr)
        sys.exit(1)

if __name__ == "__main__":
    if len(sys.argv) != 2:
        print("Usage: python speech_recognition.py <audio_file>", file=sys.stderr)
        sys.exit(1)

    audio_file = sys.argv[1]
    transcribe_audio(audio_file)
